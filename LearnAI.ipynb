{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lyKQh8Rlaz-"
      },
      "source": [
        "## **IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEJn_sgMRb1s"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random \n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras import callbacks\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UQKDl2WO5p7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1a52ae-3698-42aa-9c27-f7b7ca3d3515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading face-mask-12k-images-dataset.zip to /content\n",
            " 96% 318M/330M [00:02<00:00, 160MB/s]\n",
            "100% 330M/330M [00:02<00:00, 141MB/s]\n"
          ]
        }
      ],
      "source": [
        "#Importing data set from Kaggle\n",
        "os.environ['KAGGLE_USERNAME'] = 'yusufmoola211'\n",
        "os.environ['KAGGLE_KEY'] = '00c7ae4c784f63a68821345cd24f9474'\n",
        "! kaggle datasets download -d ashishjangra27/face-mask-12k-images-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aYed69fUh1L"
      },
      "outputs": [],
      "source": [
        "#Unzipping file\n",
        "! unzip face-mask-12k-images-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yejdxpOvVZPi"
      },
      "outputs": [],
      "source": [
        "#Directories for the three files: Test, Train and Validation\n",
        "root_dir = '/content/Face Mask Dataset'\n",
        "train_directory = os.path.join(root_dir, 'Train') \n",
        "val_directory = os.path.join(root_dir, 'Validation')\n",
        "test_directory = os.path.join(root_dir, 'Test')\n",
        "\n",
        "#Getting Mask and no mask folder within the train directory\n",
        "train_with_mask = os.path.join(train_directory, 'WithMask')\n",
        "train_without_mask = os.path.join(train_directory, 'WithoutMask')\n",
        "\n",
        "#Getting Mask and no mask folder within the valid directory\n",
        "val_with_mask = os.path.join(val_directory, 'WithMask')\n",
        "val_without_mask = os.path.join(val_directory, 'WithoutMask')\n",
        "\n",
        "#Getting Mask and no mask folder within the test directory\n",
        "\n",
        "test_with_mask = os.path.join(test_directory, 'WithMask')\n",
        "test_without_mask = os.path.join(test_directory, 'WithoutMask')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPNlce8rRQMq",
        "outputId": "3c30d478-d244-4e00-b32c-946c3d61a19c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------\n",
            "Training dataset image count:\n",
            "-------------------------------\n",
            "Number of Mask labeled images - 5000\n",
            "Number of NonMask labeled images - 5000\n",
            "\n",
            "-------------------------------\n",
            "Valid dataset image count:\n",
            "-------------------------------\n",
            "Number of Mask labeled images - 400\n",
            "Number of NonMask labeled images - 400\n",
            "\n",
            "-------------------------------\n",
            "Test dataset image count:\n",
            "-------------------------------\n",
            "Number of Mask labeled images - 483\n",
            "Number of NonMask labeled images - 509\n"
          ]
        }
      ],
      "source": [
        "# Number of images in the training dataset\n",
        "print(\"-------------------------------\")\n",
        "print('Training dataset image count:')\n",
        "print(\"-------------------------------\")\n",
        "print(\"Number of Mask labeled images -\", len(os.listdir(train_with_mask)))\n",
        "print(\"Number of NonMask labeled images -\", len(os.listdir(train_without_mask)))\n",
        "\n",
        "# Number of images in the valid dataset\n",
        "print(\"\\n-------------------------------\")\n",
        "print('Valid dataset image count:')\n",
        "print(\"-------------------------------\")\n",
        "print(\"Number of Mask labeled images -\", len(os.listdir(val_with_mask)))\n",
        "print(\"Number of NonMask labeled images -\", len(os.listdir(val_without_mask)))\n",
        "\n",
        "# Number of images in the test dataset\n",
        "print(\"\\n-------------------------------\")\n",
        "print('Test dataset image count:')\n",
        "print(\"-------------------------------\")\n",
        "print(\"Number of Mask labeled images -\", len(os.listdir(test_with_mask)))\n",
        "print(\"Number of NonMask labeled images -\", len(os.listdir(test_without_mask)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2afV6-6Vqhx",
        "outputId": "2ac3e58c-b9e5-44fa-d5b4-28f35e5395e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------\n",
            "                 TOTALS                 \n",
            "----------------------------------------\n",
            "Number of images from Training set: 10000\n",
            "Number of images from Validation set: 800\n",
            "Number of images from Test set: 992\n"
          ]
        }
      ],
      "source": [
        "#Training set with and without mask count\n",
        "num_withmask_tr = len(os.listdir(train_with_mask))\n",
        "num_withoutmask_tr = len(os.listdir(train_without_mask))\n",
        "\n",
        "#Valid set with and without mask count\n",
        "num_withmask_val = len(os.listdir(os.path.join(val_directory, 'WithMask')))\n",
        "num_withoutmask_val = len(os.listdir(os.path.join(val_directory, 'WithoutMask')))\n",
        "\n",
        "#Test set with and without mask count\n",
        "num_withmask_test = len(os.listdir(os.path.join(test_directory, 'WithMask')))\n",
        "num_withoutmask_test = len(os.listdir(os.path.join(test_directory, 'WithoutMask')))\n",
        "\n",
        "#Totals\n",
        "total_train = num_withmask_tr + num_withoutmask_tr\n",
        "total_val = num_withmask_val + num_withoutmask_val\n",
        "total_test = num_withmask_test + num_withoutmask_test\n",
        "\n",
        "\n",
        "print(\"----------------------------------------\")\n",
        "print(\"                 TOTALS                 \")\n",
        "print(\"----------------------------------------\")\n",
        "print(\"Number of images from Training set:\", total_train)\n",
        "print(\"Number of images from Validation set:\", total_val)\n",
        "print(\"Number of images from Test set:\", total_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # split training set into batches of 1000 entries each\n",
        "# nah bruh dont do this\n",
        "# use tensorflow's built in batch functionality instead\n",
        "\n",
        "# batch_threshold = 1000\n",
        "\n",
        "# train_batches = []\n",
        "# train_list = os.listdir(train_with_mask)\n",
        "\n",
        "# for i in range(len(train_list) // batch_threshold):\n",
        "#   batch_i = 'batch' + str(i)\n",
        "#   train_batches.append(os.path.join(train_with_mask, batch_i))\n",
        "\n",
        "# # print(len(os.listdir(train_with_mask)))\n",
        "\n",
        "# for i in range(len(train_list)): \n",
        "#   img = train_list[i]\n",
        "#   current_batch = i // batch_threshold\n",
        "#   new_dir = os.path.join(train_with_mask, train_batches[current_batch])\n",
        "#   shutil.copy(os.path.join(train_with_mask, img), os.path.join(new_dir, img))\n",
        "\n",
        "# # for old_img in train_list:\n",
        "# #   shutil"
      ],
      "metadata": {
        "id": "_JfrCgUn2VqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ropPM_LrUwKW"
      },
      "source": [
        "# **DATA** **VISUALIZATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NCjEbivuiPb",
        "outputId": "4038738d-903b-42c6-b447-a7f07bddb965"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Train', 'Test', 'Validation']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#Main directory that includes Test, Train and Validation dataset\n",
        "path = root_dir\n",
        "#Lists the folders in the root directory\n",
        "os.listdir(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JCTWqs6pt9m4",
        "outputId": "ad44e97a-1b74-4a29-ce70-3ba4cbe266c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         image_links     label category\n",
              "0  /content/Face Mask Dataset/Train/WithMask/Augm...  WithMask    Train\n",
              "1  /content/Face Mask Dataset/Train/WithMask/Augm...  WithMask    Train\n",
              "2  /content/Face Mask Dataset/Train/WithMask/Augm...  WithMask    Train\n",
              "3  /content/Face Mask Dataset/Train/WithMask/Augm...  WithMask    Train\n",
              "4  /content/Face Mask Dataset/Train/WithMask/Augm...  WithMask    Train"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7814488f-5b86-49cb-9771-83b9da40866b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_links</th>\n",
              "      <th>label</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/Face Mask Dataset/Train/WithMask/Augm...</td>\n",
              "      <td>WithMask</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/Face Mask Dataset/Train/WithMask/Augm...</td>\n",
              "      <td>WithMask</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/Face Mask Dataset/Train/WithMask/Augm...</td>\n",
              "      <td>WithMask</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/Face Mask Dataset/Train/WithMask/Augm...</td>\n",
              "      <td>WithMask</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/Face Mask Dataset/Train/WithMask/Augm...</td>\n",
              "      <td>WithMask</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7814488f-5b86-49cb-9771-83b9da40866b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7814488f-5b86-49cb-9771-83b9da40866b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7814488f-5b86-49cb-9771-83b9da40866b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "image_links = []\n",
        "mask_or_not = []\n",
        "category = []\n",
        "\n",
        "#loop through folders in root directory\n",
        "for folder in os.listdir(path):\n",
        "    #Loop through labels (WithMask and WithoutMask) in each folder of Test, Train and Validation\n",
        "    for label in os.listdir(path + \"/\" + folder):\n",
        "        #Gets images in each folder\n",
        "        for image in glob.glob(path+ \"/\" + folder + \"/\" + label + \"/\" + \"*.png\"):\n",
        "            image_links.append(image)\n",
        "            mask_or_not.append(label)\n",
        "            category.append(folder)\n",
        "\n",
        "\n",
        "#Making the pandas dataframe            \n",
        "data = pd.DataFrame({'image_links':image_links,'label':mask_or_not,'category':category})\n",
        "#Outputting the first 4 columns of the dataframe as a sample view\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMwrXH50RpNO"
      },
      "outputs": [],
      "source": [
        "#Seperarting the data frame into train, test and val through filter operations\n",
        "train_data =data[data['category']=='Train'].sample(frac=1)\n",
        "test_data = data[data['category']=='Test'].sample(frac=1)\n",
        "validation = data[data['category']=='Validation'].sample(frac=1) \n",
        "\n",
        "#btw frac=1 just means getting 100% of the row data to return\n",
        "\n",
        "#Variables for the image paths of each set (Train, test and valid)\n",
        "train_path = train_data.image_links\n",
        "test_path = test_data.image_links\n",
        "valid_path = validation.image_links\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVF9ffJpRq3_"
      },
      "outputs": [],
      "source": [
        "#Function to plot the images\n",
        "def plot_images(data):\n",
        "    for index in range(10):\n",
        "\n",
        "        #Getting image from dataframe, opencv used to read image from path\n",
        "        plt.imshow(cv2.imread(data.iloc[index,0]))\n",
        "\n",
        "        #Adding title to the image for the label and which category it belongs to\n",
        "        plt.title('{}:{}'.format(data.iloc[index,1],data.iloc[index,2]))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0R5x6aRRuYv"
      },
      "outputs": [],
      "source": [
        "plot_images(validation)\n",
        "plot_images(train_data)\n",
        "plot_images(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LABELS AND PREPROCESSING**"
      ],
      "metadata": {
        "id": "dcZJdYG6q3o9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the classes\n",
        "classes = ['WithMask', 'WithoutMask']\n",
        "\"\"\"\n",
        "# Define a function to load and preprocess the images\n",
        "def load_image(path):\n",
        "    # Load the image and resize it\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    \n",
        "    # Preprocess the image\n",
        "    img = img / 255.0\n",
        "    img = np.array(img)\n",
        "    \n",
        "    return img\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "icldD7rHuXpx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "1453791f-d436-4e26-b15b-80cf8ab5fab2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Define a function to load and preprocess the images\\ndef load_image(path):\\n    # Load the image and resize it\\n    img = cv2.imread(path)\\n    img = cv2.resize(img, (224,224))\\n    \\n    # Preprocess the image\\n    img = img / 255.0\\n    img = np.array(img)\\n    \\n    return img\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(train_directory,\n",
        "                                                       batch_size=total_train,\n",
        "                                                       image_size=(224,224),\n",
        "                                                       shuffle=True)\n",
        "validation_ds = tf.keras.utils.image_dataset_from_directory(val_directory,\n",
        "                                                            batch_size=total_val,\n",
        "                                                            image_size=(224,224),\n",
        "                                                            shuffle=True)\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(test_directory,\n",
        "                                                      batch_size=total_test,\n",
        "                                                      image_size=(224,224),\n",
        "                                                      shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rublynt8vcf2",
        "outputId": "b66f5199-2f44-414d-d3ee-a260fd232031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 files belonging to 2 classes.\n",
            "Found 800 files belonging to 2 classes.\n",
            "Found 992 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJtL-DLcX9df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "8c03971d-90ad-4517-eb9a-4ce89536752d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntrain_images = []\\ntrain_labels = []\\n\\ndef load_train():\\n  for c in classes:\\n      class_path = os.path.join(train_directory, c)\\n      class_list = os.listdir(class_path)\\n      for image_path in class_list:\\n          img = load_image(os.path.join(class_path, image_path))\\n          train_images.append(img)\\n          train_labels.append(classes.index(c))\\n\\n  # Convert the lists to numpy arrays\\n  train_images = np.array(train_images)\\n  train_labels = np.array(train_labels)\\n\\n# Load the validation images\\nval_images = []\\nval_labels = []\\n\\nfor c in classes:\\n    class_path = os.path.join(val_directory, c)\\n    for image_path in os.listdir(class_path):\\n        img = load_image(os.path.join(class_path, image_path))\\n        val_images.append(img)\\n        val_labels.append(classes.index(c))\\n\\n# Convert the lists to numpy arrays\\nval_images = np.array(val_images)\\nval_labels = np.array(val_labels)\\n\\n# Load the test images\\ntest_images = []\\ntest_labels = []\\nfor c in classes:\\n    class_path = os.path.join(test_directory, c)\\n    for image_path in os.listdir(class_path):\\n        img = load_image(os.path.join(class_path, image_path))\\n        test_images.append(img)\\n        test_labels.append(classes.index(c))\\n\\n# Convert the lists to numpy arrays\\ntest_images = np.array(test_images)\\ntest_labels = np.array(test_labels)\\n\\n# Convert the labels to categorical format\\ntrain_labels = tf.keras.utils.to_categorical(train_labels, len(classes))\\nval_labels = tf.keras.utils.to_categorical(val_labels, len(classes))\\ntest_labels = tf.keras.utils.to_categorical(test_labels, len(classes))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Load the training images in batches\n",
        "\"\"\"\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "def load_train():\n",
        "  for c in classes:\n",
        "      class_path = os.path.join(train_directory, c)\n",
        "      class_list = os.listdir(class_path)\n",
        "      for image_path in class_list:\n",
        "          img = load_image(os.path.join(class_path, image_path))\n",
        "          train_images.append(img)\n",
        "          train_labels.append(classes.index(c))\n",
        "\n",
        "  # Convert the lists to numpy arrays\n",
        "  train_images = np.array(train_images)\n",
        "  train_labels = np.array(train_labels)\n",
        "\n",
        "# Load the validation images\n",
        "val_images = []\n",
        "val_labels = []\n",
        "\n",
        "for c in classes:\n",
        "    class_path = os.path.join(val_directory, c)\n",
        "    for image_path in os.listdir(class_path):\n",
        "        img = load_image(os.path.join(class_path, image_path))\n",
        "        val_images.append(img)\n",
        "        val_labels.append(classes.index(c))\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "val_images = np.array(val_images)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Load the test images\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for c in classes:\n",
        "    class_path = os.path.join(test_directory, c)\n",
        "    for image_path in os.listdir(class_path):\n",
        "        img = load_image(os.path.join(class_path, image_path))\n",
        "        test_images.append(img)\n",
        "        test_labels.append(classes.index(c))\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "test_images = np.array(test_images)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "# Convert the labels to categorical format\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, len(classes))\n",
        "val_labels = tf.keras.utils.to_categorical(val_labels, len(classes))\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, len(classes))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# autotune buffer to avoid I/0 block\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "validation_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "mWxyuuqU6Fc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Rescaling(1./255),\n",
        "  tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)), #128x128\n",
        "  tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)), #64x64\n",
        "  tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)), #32x32\n",
        "  tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
        "  tf.keras.layers.MaxPooling2D(pool_size=(2,2)), #16x16\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(num_classes, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "e8GF_hUWuJJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "a8O9KP5guTY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining callback function to avoid overfit\n",
        "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
        "                                        mode =\"min\", patience = 6, \n",
        "                                        restore_best_weights = True, verbose=1)"
      ],
      "metadata": {
        "id": "848qoHwPuWMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=validation_ds,\n",
        "  epochs=1,\n",
        "  callbacks =[earlystopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "JGZ0LkwY6edP",
        "outputId": "c44a4ad3-3a19-4603-a3d5-0c32f4083fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b04e3309138b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlystopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e = model.evaluate(test_ds)\n",
        "\n",
        "print(f'Test set accuracy: {\"{0:.2f}\".format(e[1]*100)}%')"
      ],
      "metadata": {
        "id": "9ryo15oY6gV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp1069WnmK_P"
      },
      "source": [
        "# **Face Detection from image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyqc5cF2F457"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf10x2eZGZ2R"
      },
      "outputs": [],
      "source": [
        "base_dir = '/content/drive/My Drive/UofT AI project google collab/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2GFuTa8DRyL"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Read the input image\n",
        "img = cv2.imread(base_dir + 'img/people.jpg')\n",
        "  \n",
        "# convert to grayscale of each frames\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# read the haarcascade to detect the faces in an image\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
        "\n",
        "# detects faces in the input image\n",
        "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "print('Number of detected faces:', len(faces))\n",
        "\n",
        "# loop over all detected faces\n",
        "if len(faces) > 0:\n",
        "   for i, (x,y,w,h) in enumerate(faces):\n",
        "      \n",
        "      # To draw a rectangle in a face\n",
        "      cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
        "      face = img[y:y+h, x:x+w]\n",
        "      cv2_imshow(face)\n",
        "      cv2.imwrite(f'face{i}.jpg', face)\n",
        "      print(f\"face{i}.jpg is saved\")\n",
        "\n",
        "# display the image with detected faces\n",
        "cv2_imshow(img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}